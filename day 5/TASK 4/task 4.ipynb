{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1 TF-IDF scores:\n",
      "  the: 0.0000\n",
      "  player: 0.0770\n",
      "  made: 0.0770\n",
      "  a: 0.0770\n",
      "  fantastic: 0.0770\n",
      "  goal: -0.0248\n",
      "  during: 0.0770\n",
      "  match: 0.0320\n",
      "\n",
      "Document 2 TF-IDF scores:\n",
      "  what: 0.1155\n",
      "  an: 0.1155\n",
      "  incredible: 0.1155\n",
      "  goal: -0.0372\n",
      "  that: 0.1155\n",
      "  was: 0.0479\n",
      "\n",
      "Document 3 TF-IDF scores:\n",
      "  the: 0.0000\n",
      "  match: 0.0262\n",
      "  was: 0.0262\n",
      "  intense: 0.0630\n",
      "  and: 0.0630\n",
      "  crowd: 0.0630\n",
      "  cheered: 0.0630\n",
      "  for: 0.0630\n",
      "  every: 0.0630\n",
      "  goal: -0.0203\n",
      "\n",
      "Document 4 TF-IDF scores:\n",
      "  the: 0.0000\n",
      "  commentator: 0.0578\n",
      "  praised: 0.0578\n",
      "  goal: -0.0186\n",
      "  as: 0.0578\n",
      "  one: 0.0578\n",
      "  of: 0.0578\n",
      "  best: 0.0578\n",
      "  this: 0.0578\n",
      "  season: 0.0578\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "def tokenize(text):\n",
    "    \"\"\"Simple tokenization by splitting on spaces and removing punctuation.\"\"\"\n",
    "    return [word.lower().strip('.,!?') for word in text.split()]\n",
    "\n",
    "def compute_tf(document):\n",
    "    \"\"\"Compute term frequency (TF) for each word in the document.\"\"\"\n",
    "    word_count = Counter(tokenize(document))\n",
    "    total_words = len(tokenize(document))\n",
    "    return {word: count / total_words for word, count in word_count.items()}\n",
    "\n",
    "def compute_idf(documents):\n",
    "    \"\"\"Compute inverse document frequency (IDF) for each word across documents.\"\"\"\n",
    "    total_docs = len(documents)\n",
    "    word_in_docs = Counter()\n",
    "    for doc in documents:\n",
    "        unique_words = set(tokenize(doc))\n",
    "        for word in unique_words:\n",
    "            word_in_docs[word] += 1\n",
    "    return {word: math.log(total_docs / (1 + count)) for word, count in word_in_docs.items()}\n",
    "\n",
    "def compute_tfidf(documents):\n",
    "    \"\"\"Compute TF-IDF scores for all documents.\"\"\"\n",
    "    idf = compute_idf(documents)\n",
    "    tfidf_scores = []\n",
    "    for doc in documents:\n",
    "        tf = compute_tf(doc)\n",
    "        tfidf = {word: tf[word] * idf[word] for word in tf}\n",
    "        tfidf_scores.append(tfidf)\n",
    "    return tfidf_scores\n",
    "documents = [\n",
    "    \"The player made a fantastic goal during the match.\",\n",
    "    \"What an incredible goal that was!\",\n",
    "    \"The match was intense, and the crowd cheered for every goal.\",\n",
    "    \"The commentator praised the goal as one of the best this season.\"\n",
    "]\n",
    "tfidf_scores = compute_tfidf(documents)\n",
    "for i, doc_tfidf in enumerate(tfidf_scores):\n",
    "    print(f\"Document {i+1} TF-IDF scores:\")\n",
    "    for word, score in doc_tfidf.items():\n",
    "        print(f\"  {word}: {score:.4f}\")\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
